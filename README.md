# Deep-Learning

## CMP784: Deep Learning
- you can find a good course that provides a thorough understanding of the fundamental concepts and recent advances in deep learning 
<a href="https://web.cs.hacettepe.edu.tr/~aykut/classes/spring2018/cmp784/index.html#div_courseinfo"> here </a> by
<a href="https://web.cs.hacettepe.edu.tr/~aykut/"> Aykut Erdem </a>.

&rarr; Useful Information About Deep Learning

- In the following address(Useful and attractive!) you can find Practical courses about "Deep Learning" :
 https://handong1587.github.io/deep_learning/2015/10/09/dl-courses.html
 
 
 &#10039; another useful LINK:  
 - <a href="http://deeplearning.lipingyang.org/">Deep Learning Garden</a>: Liping's machine learning, computer vision, and deep learning home: resources about basics, applications, and many more…
 - http://deeplearning.cs.cmu.edu/
 -  the page "<a href="https://distill.pub/2017/momentum/" >Why Momentum Really Works</a>" is a popular story about momentum by <a href="http://gabgoh.github.io/"> Gabriel Goh </a>.
 - <a href="https://www.quora.com/What-does-end-to-end-mean-in-deep-learning-methods">What does end to end mean in deep learning methods?</a>
 - <a href="https://www.zerotodeeplearning.com/bootcamp?utm_expid=.gXYlB1rUTiOTz74Mmxzc_g.1&utm_referrer=https%3A%2F%2Fwww.google.com%2F#what-will-i-learn">Zero to Deep Learning</a>; San Francisco’s leading machine & deep learning bootcamp.
## Optimization
- Useful links and papers:

    &clubs; <a href="https://www.learnopencv.com/batch-normalization-in-deep-networks/">Batch Normalization in Deep Networks</a> by Sunita Nayak
    
    &clubs; <a href="https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9">Epoch vs Batch Size vs Iterations</a> by SAGAR SHARMA
 
## Convolutional Networks
- Useful links and papers:

   &diams; <a href="https://www.geeksforgeeks.org/depth-wise-separable-convolutional-neural-networks/"> Depth wise Separable Convolutional Neural Networks </a> 
   
   &diams; <a href="https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728"> A Basic Introduction to Separable Convolutions </a> by Chi Feng Wang


## RECURRENT AND RECURSIVE NEURAL NETWORKS
- Useful links and papers:

    &spades; <a href="https://arxiv.org/pdf/1803.07870.pdf"> Reservoir computing </a>
    
    &spades; <a href="https://towardsdatascience.com/gentle-introduction-to-echo-state-networks-af99e5373c68"> Gentle introduction to Echo State Networks </a>

    &spades; <a href="https://towardsdatascience.com/animated-rnn-lstm-and-gru-ef124d06cf45"> Animated RNN, LSTM and GRU </a>

    &spades; <a href= "https://www.researchgate.net/post/what_is_the_realitionship_between_deep_learning_methods_and_reservoir_computing_if_any">
 What is the realitionship between deep learning methods and reservoir computing (if any)?</a>
 ## Autoencoder
 - Useful links and papers:
 
   &clubs; <a href="https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf">Sparse Autoencoder</a>; Lecture note by Andrew Ng
 
   &clubs; <a href="https://towardsdatascience.com/paper-summary-iclr-2014-k-sparse-autoencoders-72078c6f1117">k-Sparse Autoencoders</a>
   
   &clubs; <a href="https://jaan.io/what-is-variational-autoencoder-vae-tutorial/">Tutorial - What is a variational autoencoder?</a>by <a href="https://jaan.io/">JAAN ALTOSAAR</a>
   
   &clubs; A good <a href="https://www.cse.cuhk.edu.hk/irwin.king/_media/presentations/autoencoder_part1.pdf">PowerPoint</a> by Shilin HE
 ## Main TextBooks
 <img src="https://github.com/Erfaan-Rostami/Deep-Learning/blob/master/Chollet-DLP-HI.png"  title="pro deep learning with tensorflow" height="140" width="120" /><img src="https://github.com/Erfaan-Rostami/Deep-Learning/blob/master/pro%20deep%20learning%20with%20tensorflow.jpg"  title="pro deep learning with tensorflow" height="140" width="120" /><img src="https://github.com/Erfaan-Rostami/Deep-Learning/blob/master/DL-Goodfellow.jpg"  title="pro deep learning with tensorflow" height="140" width="120" /><img src="https://github.com/Erfaan-Rostami/Deep-Learning/blob/master/JBrownlee.png"  title="Better Deep Learning" height="140" width="120" />
 
 &hearts; <a href="https://machinelearningmastery.com/better-deep-learning/">"Better Deep Learning"</a>; a new eBook  written by <a href="https://github.com/jbrownlee">Jason Brownlee</a> in the friendly Machine Learning Mastery style that you’re used to, discover exactly how to improve the performance of deep learning neural network models on your predictive modeling projects.
 ## Google Colab and Anaconda
 - <a href="https://colab.research.google.com/notebooks/welcome.ipynb">Google Colab</a> provides GPU and it’s totally free. Seriously!
 
 - A <a href="https://towardsdatascience.com/getting-started-with-google-colab-f2fff97f594c">Simple Tutorial</a> for the Frustrated and Confused, by Anne Bonner
 - <a href="https://medium.com/lean-in-women-in-tech-india/google-colab-the-beginners-guide-5ad3b417dfa">Google Colab</a> - The Beginner’s Guide, by Vishakha Lall
 - <a href="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#managing-environments">Managing environments</a>
 - <a href="http://deeplearning.lipingyang.org/2018/12/25/conda-commands-create-virtual-environments-for-python-with-conda/">Conda commands</a>(create virtual environments for python with conda)
## About Keras:
&#8669; Keras is a Deep Learning library for Python, that is simple, modular, and extensible.

&#10022; <a href="https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/">How to Configure Image Data Augmentation in Keras</a>; by Jason Brownlee

&#10022; <a href="https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/">Keras ImageDataGenerator and Data Augmentation</a>; by Adrian Rosebrock

&#10022; <a href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html">Building powerful image classification models using very little data</a>
## Regularization 
Many strategiesused in machine learning are explicitly designed to reduce the test error, possiblyat the expense of increased training error. These strategies are known collectivelyas regularization.

&#10020; <a href="https://www.deeplearningbook.org/contents/regularization.html">Chapter 7</a> of the Deep Learning textbook.

&#10020; <a href="">An Overview of Regularization Techniques in Deep Learning (with Python code)</a>, by SHUBHAM JAIN

&#10020; <a href="">How to Improve a Neural Network With Regularization</a>(with code for L2 regularization and dropout), by Marco Peixeiro


